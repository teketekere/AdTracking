{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 46 s\n",
      "[Generating str_array] done in 124 s\n",
      "Training 10000000 250.3038763999939\n",
      "memory GB: 2.343250274658203\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 48 s\n",
      "[Generating str_array] done in 135 s\n",
      "Training 20000000 632.2305178642273\n",
      "memory GB: 2.345611572265625\n",
      "20000000 ROC AUC: 0.9784917614067113 Running Mean: 0.9784917614067113\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 46 s\n",
      "[Generating str_array] done in 128 s\n",
      "Training 30000000 1008.5262680053711\n",
      "memory GB: 2.3476600646972656\n",
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 45 s\n",
      "[Generating str_array] done in 126 s\n",
      "Training 40000000 1350.1666157245636\n",
      "memory GB: 2.4215431213378906\n",
      "40000000 ROC AUC: 0.9785338228058769 Running Mean: 0.9785001736865445\n",
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 46 s\n",
      "[Generating str_array] done in 126 s\n",
      "Training 50000000 1711.0882148742676\n",
      "memory GB: 2.3464202880859375\n",
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 45 s\n",
      "[Generating str_array] done in 139 s\n",
      "Training 60000000 2071.758841276169\n",
      "memory GB: 2.418842315673828\n",
      "60000000 ROC AUC: 0.9869115528564167 Running Mean: 0.9801824495205189\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 48 s\n",
      "[Generating str_array] done in 139 s\n",
      "Training 70000000 2463.0470366477966\n",
      "memory GB: 2.3434829711914062\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 48 s\n",
      "[Generating str_array] done in 127 s\n",
      "Training 80000000 2819.3879673480988\n",
      "memory GB: 2.3445396423339844\n",
      "80000000 ROC AUC: 0.9811081554168775 Running Mean: 0.9803675906997906\n",
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 47 s\n",
      "[Generating str_array] done in 142 s\n",
      "Training 90000000 3203.380478620529\n",
      "memory GB: 2.34588623046875\n",
      "[Adding counts] done in 14 s\n",
      "[Adding next click times] done in 50 s\n",
      "[Generating str_array] done in 133 s\n",
      "Training 100000000 3601.917553663254\n",
      "memory GB: 2.386554718017578\n",
      "100000000 ROC AUC: 0.9817417715281918 Running Mean: 0.980642426865471\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 49 s\n",
      "[Generating str_array] done in 148 s\n",
      "Training 110000000 4018.6901309490204\n",
      "memory GB: 2.3783226013183594\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 51 s\n",
      "[Generating str_array] done in 129 s\n",
      "Training 120000000 4401.916058301926\n",
      "memory GB: 2.3781776428222656\n",
      "120000000 ROC AUC: 0.9861376828723852 Running Mean: 0.981741478066854\n",
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 44 s\n",
      "[Generating str_array] done in 124 s\n",
      "Training 130000000 4762.911359548569\n",
      "memory GB: 2.4143142700195312\n",
      "[Adding counts] done in 12 s\n",
      "[Adding next click times] done in 45 s\n",
      "[Generating str_array] done in 124 s\n",
      "Training 140000000 5120.49720621109\n",
      "memory GB: 2.451213836669922\n",
      "140000000 ROC AUC: 0.9783235988294587 Running Mean: 0.981057902219375\n",
      "[Adding counts] done in 14 s\n",
      "[Adding next click times] done in 52 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 150000000 5554.185457229614\n",
      "memory GB: 2.4189186096191406\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 46 s\n",
      "[Generating str_array] done in 132 s\n",
      "Training 160000000 5913.318136930466\n",
      "memory GB: 2.4265823364257812\n",
      "160000000 ROC AUC: 0.9774611150114365 Running Mean: 0.9803385447777875\n",
      "[Adding counts] done in 14 s\n",
      "[Adding next click times] done in 47 s\n",
      "[Generating str_array] done in 126 s\n",
      "Training 170000000 6291.722777366638\n",
      "memory GB: 2.4254989624023438\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 50 s\n",
      "[Generating str_array] done in 137 s\n",
      "Training 180000000 6682.884987354279\n",
      "memory GB: 2.5008316040039062\n",
      "180000000 ROC AUC: 0.9837952113912616 Running Mean: 0.9810298781004824\n",
      "[Adding counts] done in 6 s\n",
      "[Adding next click times] done in 23 s\n",
      "[Generating str_array] done in 65 s\n",
      "Training 190000000 6958.224002838135\n",
      "memory GB: 1.2639007568359375\n",
      "[Adding counts] done in 13 s\n",
      "[Adding next click times] done in 49 s\n",
      "[Generating str_array] done in 134 s\n",
      "[Adding counts] done in 11 s\n",
      "[Adding next click times] done in 43 s\n",
      "[Generating str_array] done in 112 s\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path.insert(0, '../input/wordbatch-133/wordbatch/')\n",
    "# sys.path.insert(0, '../input/randomstate/randomstate/')\n",
    "import wordbatch\n",
    "from wordbatch.extractors import WordHash\n",
    "from wordbatch.models import FM_FTRL\n",
    "from wordbatch.data_utils import *\n",
    "import threading\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "import os, psutil\n",
    "def cpuStats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print('memory GB:', memoryUse)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mean_auc= 0\n",
    "\n",
    "def fit_batch(clf, X, y, w):  clf.partial_fit(X, y, sample_weight=w)\n",
    "\n",
    "def predict_batch(clf, X):  return clf.predict(X)\n",
    "\n",
    "def evaluate_batch(clf, X, y, rcount):\n",
    "    auc= roc_auc_score(y, predict_batch(clf, X))\n",
    "    global mean_auc\n",
    "    if mean_auc==0:\n",
    "        mean_auc= auc\n",
    "    else: mean_auc= 0.2*(mean_auc*4 + auc)\n",
    "    print(rcount, \"ROC AUC:\", auc, \"Running Mean:\", mean_auc)\n",
    "    return auc\n",
    "\n",
    "def df_add_counts(df, cols):\n",
    "    arr_slice = df[cols].values\n",
    "    unq, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(0) + 1),\n",
    "                                     return_inverse=True, return_counts=True)\n",
    "    df[\"_\".join(cols)+'_count'] = counts[unqtags]\n",
    "\n",
    "def df2csr(wb, df, pick_hours=None):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    with timer(\"Adding counts\"):\n",
    "        df['click_time']= pd.to_datetime(df['click_time'])\n",
    "        dt= df['click_time'].dt\n",
    "        df['day'] = dt.day.astype('uint8')\n",
    "        df['hour'] = dt.hour.astype('uint8')\n",
    "        del(dt)\n",
    "        df_add_counts(df, ['ip', 'day', 'hour'])\n",
    "        df_add_counts(df, ['ip', 'app'])\n",
    "        df_add_counts(df, ['ip', 'app', 'os'])\n",
    "        df_add_counts(df, ['ip', 'device'])\n",
    "        df_add_counts(df, ['app', 'channel'])\n",
    "        #cpuStats()\n",
    "\n",
    "    with timer(\"Adding next click times\"):\n",
    "        D= 2**26\n",
    "        df['category'] = (df['ip'].astype(str) + \"_\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n",
    "                         + \"_\" + df['os'].astype(str)).apply(hash) % D\n",
    "        click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "        df['epochtime']= df['click_time'].astype(np.int64) // 10 ** 9\n",
    "        next_clicks= []\n",
    "        for category, time in zip(reversed(df['category'].values), reversed(df['epochtime'].values)):\n",
    "            next_clicks.append(click_buffer[category]-time)\n",
    "            click_buffer[category]= time\n",
    "        del(click_buffer)\n",
    "        df['next_click']= list(reversed(next_clicks))\n",
    "\n",
    "    for fea in ['ip_day_hour_count','ip_app_count','ip_app_os_count','ip_device_count',\n",
    "                'app_channel_count','next_click']:  df[fea]= np.log2(1 + df[fea].values).astype(int)\n",
    "\n",
    "    with timer(\"Generating str_array\"):\n",
    "        str_array= (\"I\" + df['ip'].astype(str) \\\n",
    "            + \" A\" + df['app'].astype(str) \\\n",
    "            + \" D\" + df['device'].astype(str) \\\n",
    "            + \" O\" + df['os'].astype(str) \\\n",
    "            + \" C\" + df['channel'].astype(str) \\\n",
    "            + \" WD\" + df['day'].astype(str) \\\n",
    "            + \" H\" + df['hour'].astype(str) \\\n",
    "            + \" AXC\" + df['app'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "            + \" OXC\" + df['os'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "            + \" AXD\" + df['app'].astype(str)+\"_\"+df['device'].astype(str) \\\n",
    "            + \" IXA\" + df['ip'].astype(str)+\"_\"+df['app'].astype(str) \\\n",
    "            + \" AXO\" + df['app'].astype(str)+\"_\"+df['os'].astype(str) \\\n",
    "            + \" IDHC\" + df['ip_day_hour_count'].astype(str) \\\n",
    "            + \" IAC\" + df['ip_app_count'].astype(str) \\\n",
    "            + \" AOC\" + df['ip_app_os_count'].astype(str) \\\n",
    "            + \" IDC\" + df['ip_device_count'].astype(str) \\\n",
    "            + \" AC\" + df['app_channel_count'].astype(str) \\\n",
    "            + \" NC\" + df['next_click'].astype(str)\n",
    "          ).values\n",
    "    #cpuStats()\n",
    "    if 'is_attributed' in df.columns:\n",
    "        labels = df['is_attributed'].values\n",
    "        weights = np.multiply([1.0 if x == 1 else 0.2 for x in df['is_attributed'].values],\n",
    "                              df['hour'].apply(lambda x: 1.0 if x in pick_hours else 0.5))\n",
    "    else:\n",
    "        labels = []\n",
    "        weights = []\n",
    "    return str_array, labels, weights\n",
    "\n",
    "class ThreadWithReturnValue(threading.Thread):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None):\n",
    "        threading.Thread.__init__(self, group, target, name, args, kwargs, daemon=daemon)\n",
    "        self._return = None\n",
    "    def run(self):\n",
    "        if self._target is not None:\n",
    "            self._return = self._target(*self._args, **self._kwargs)\n",
    "    def join(self):\n",
    "        threading.Thread.join(self)\n",
    "        return self._return\n",
    "\n",
    "batchsize = 10000000\n",
    "D = 2 ** 20\n",
    "\n",
    "wb = wordbatch.WordBatch(None, extractor=(WordHash, {\"ngram_range\": (1, 1), \"analyzer\": \"word\",\n",
    "                                                     \"lowercase\": False, \"n_features\": D,\n",
    "                                                     \"norm\": None, \"binary\": True})\n",
    "                         , minibatch_size=batchsize // 80, procs=8, freeze=True, timeout=1800, verbose=0)\n",
    "clf = FM_FTRL(alpha=0.05, beta=0.1, L1=0.0, L2=0.0, D=D, alpha_fm=0.02, L2_fm=0.0, init_fm=0.01, weight_fm=1.0,\n",
    "              D_fm=8, e_noise=0.0, iters=3, inv_link=\"sigmoid\", e_clip=1.0, threads=4, use_avx=1, verbose=0)\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        }\n",
    "\n",
    "p = None\n",
    "rcount = 0\n",
    "for df_c in pd.read_csv('../input/train.csv', engine='c', chunksize=batchsize, sep=\",\", dtype=dtypes):\n",
    "    rcount += batchsize\n",
    "    str_array, labels, weights= df2csr(wb, df_c, pick_hours={4, 5, 10, 13, 14})\n",
    "    del(df_c)\n",
    "    if p != None:\n",
    "        p.join()\n",
    "        del(X)\n",
    "    gc.collect()\n",
    "    X= wb.transform(str_array)\n",
    "    del(str_array)\n",
    "    if rcount % (2 * batchsize) == 0:\n",
    "        if p != None:  p.join()\n",
    "        p = threading.Thread(target=evaluate_batch, args=(clf, X, labels, rcount))\n",
    "        p.start()\n",
    "    print(\"Training\", rcount, time.time() - start_time)\n",
    "    cpuStats()\n",
    "    if p != None:  p.join()\n",
    "    p = threading.Thread(target=fit_batch, args=(clf, X, labels, weights))\n",
    "    p.start()\n",
    "if p != None:  p.join()\n",
    "\n",
    "del(X)\n",
    "p = None\n",
    "click_ids= []\n",
    "test_preds = []\n",
    "rcount = 0\n",
    "for df_c in pd.read_csv('../input/test.csv', engine='c', chunksize=batchsize, sep=\",\", dtype=dtypes):\n",
    "    rcount += batchsize\n",
    "    if rcount % (10 * batchsize) == 0:\n",
    "        print(rcount)\n",
    "    str_array, labels, weights = df2csr(wb, df_c)\n",
    "    click_ids+= df_c['click_id'].tolist()\n",
    "    del(df_c)\n",
    "    if p != None:\n",
    "        test_preds += list(p.join())\n",
    "        del (X)\n",
    "    gc.collect()\n",
    "    X = wb.transform(str_array)\n",
    "    del (str_array)\n",
    "    p = ThreadWithReturnValue(target=predict_batch, args=(clf, X))\n",
    "    p.start()\n",
    "if p != None:  test_preds += list(p.join())\n",
    "\n",
    "df_sub = pd.DataFrame({\"click_id\": click_ids, 'is_attributed': test_preds})\n",
    "df_sub.to_csv(\"wordbatch_fm_ftrl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
