{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "61000000\n",
      "loading train data... 1000000 61000000\n",
      "loading test data...\n",
      "Extracting new features...\n",
      "Doing nextClick...\n",
      "Elapsed: 41.5444974899292 seconds\n",
      "Extracting aggregation features...\n",
      "Counting unqiue  channel  by  ['ip'] ...\n",
      "X0 max value =  147\n",
      "Counting unqiue  app  by  ['ip'] ...\n",
      "X3 max value =  235\n",
      "Counting unqiue  device  by  ['ip'] ...\n",
      "X5 max value =  349\n",
      "Counting unqiue  app  by  ['ip', 'device', 'os'] ...\n",
      "X8 max value =  100\n",
      "Aggregating by  ['ip', 'hour'] ...\n",
      "ip_tcount max value =  84289\n",
      "Aggregating by  ['ip', 'app'] ...\n",
      "ip_app_count max value =  82004\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78790469 entries, 0 to 78790468\n",
      "Data columns (total 15 columns):\n",
      "app              uint16\n",
      "channel          uint16\n",
      "click_id         uint32\n",
      "device           uint16\n",
      "ip               uint32\n",
      "is_attributed    uint8\n",
      "os               uint16\n",
      "hour             uint8\n",
      "nextClick        int32\n",
      "X0               uint8\n",
      "X3               uint8\n",
      "X5               uint16\n",
      "X8               uint32\n",
      "ip_tcount        uint32\n",
      "ip_app_count     uint32\n",
      "dtypes: int32(1), uint16(5), uint32(5), uint8(4)\n",
      "memory usage: 3.4 GB\n",
      "label encoding....\n",
      "predictors ['nextClick', 'app', 'device', 'os', 'channel', 'hour', 'ip_tcount', 'ip_app_count', 'X0', 'X3', 'X5', 'X8']\n",
      "train size:  58000000\n",
      "valid size:  2000000\n",
      "test size :  18790469\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58000000 entries, 0 to 57999999\n",
      "Data columns (total 12 columns):\n",
      "app             uint16\n",
      "channel         uint16\n",
      "device          uint16\n",
      "os              uint16\n",
      "hour            uint8\n",
      "nextClick       int32\n",
      "X0              uint8\n",
      "X3              uint8\n",
      "X5              uint16\n",
      "X8              uint32\n",
      "ip_tcount       uint16\n",
      "ip_app_count    uint16\n",
      "dtypes: int32(1), uint16(7), uint32(1), uint8(3)\n",
      "memory usage: 1.8 GB\n",
      "Training...\n",
      "neural network....\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "app (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ch (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dev (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "os (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "nc (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ipc (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ipac (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X0 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X3 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X5 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X8 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 50)        33850       app[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 50)        24950       ch[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 50)        177300      dev[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 50)        37450       os[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 50)        1200        h[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 50)        17029250    nc[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 50)        2809150     ipc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 50)        3193650     ipac[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 50)        7400        X0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 50)        11800       X3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 50)        17500       X5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 50)        5050        X8[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 600)       0           embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "                                                                 embedding_21[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "                                                                 embedding_23[0][0]               \n",
      "                                                                 embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 600)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 600)          0           spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1000)         601000      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1000)         1001000     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            1001        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,951,551\n",
      "Trainable params: 24,951,551\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 58000000 samples, validate on 2000000 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[10958,0] = 801 is not in [0, 749)\n\t [[Node: embedding_16/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_16/embeddings/read, embedding_16/Cast, embedding_13/GatherV2/axis)]]\n\nCaused by op 'embedding_16/GatherV2', defined at:\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-aeb3ab3acb67>\", line 239, in <module>\n    emb_os = Embedding(max_os, emb_n)(in_os)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1215, in gather\n    return tf.gather(reference, indices)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3668, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[10958,0] = 801 is not in [0, 749)\n\t [[Node: embedding_16/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_16/embeddings/read, embedding_16/Cast, embedding_13/GatherV2/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[10958,0] = 801 is not in [0, 749)\n\t [[Node: embedding_16/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_16/embeddings/read, embedding_16/Cast, embedding_13/GatherV2/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-aeb3ab3acb67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m.99\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# magic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dl_support.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[0;32m   1249\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m                                                        verbose=0)\n\u001b[0m\u001b[0;32m   1251\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1424\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1427\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[10958,0] = 801 is not in [0, 749)\n\t [[Node: embedding_16/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_16/embeddings/read, embedding_16/Cast, embedding_13/GatherV2/axis)]]\n\nCaused by op 'embedding_16/GatherV2', defined at:\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-aeb3ab3acb67>\", line 239, in <module>\n    emb_os = Embedding(max_os, emb_n)(in_os)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1215, in gather\n    return tf.gather(reference, indices)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3668, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ahega\\Anaconda3\\envs\\tensorflow16\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[10958,0] = 801 is not in [0, 749)\n\t [[Node: embedding_16/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_16/embeddings/read, embedding_16/Cast, embedding_13/GatherV2/axis)]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Change DEBUG to False and the kernel should take 5 hours to run on Kaggle\n",
    "DEBUG = False\n",
    "WHERE = 'kaggle'\n",
    "FILENO = 4\n",
    "NCHUNK = 60000000\n",
    "OFFSET =  184903890-1000000\n",
    "VAL_RUN = False\n",
    "\n",
    "MISSING32 = 999999999\n",
    "MISSING8 = 255\n",
    "PUBLIC_CUTOFF = 4032690\n",
    "\n",
    "if WHERE=='kaggle':\n",
    "    inpath = '../input/'\n",
    "    pickle_path ='../input/'\n",
    "    suffix = ''\n",
    "    outpath = ''\n",
    "    savepath = ''\n",
    "    oofpath = ''\n",
    "    cores = 4\n",
    "elif WHERE=='gcloud':\n",
    "    inpath = '../.kaggle/competitions/talkingdata-adtracking-fraud-detection/'\n",
    "    pickle_path = '../data/'\n",
    "    suffix = '.zip'\n",
    "    outpath = '../sub/'\n",
    "    oofpath = '../oof/'\n",
    "    savepath = '../data/'\n",
    "    cores = 7\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def do_count( df, group_cols, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols , '...' )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "def do_countuniq( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Counting unqiue \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "    \n",
    "debug = DEBUG\n",
    "if debug:\n",
    "    print('*** debug parameter set: this is a test run for debugging purposes ***')\n",
    "\n",
    "    \n",
    "if VAL_RUN:\n",
    "    nrows=122071522\n",
    "    outpath = oofpath\n",
    "else:\n",
    "    nrows=184903890\n",
    "nchunk=NCHUNK\n",
    "val_size=2000000\n",
    "frm = nrows - OFFSET\n",
    "if debug:\n",
    "    frm=0\n",
    "    nchunk=100000\n",
    "    val_size=10000\n",
    "to=frm+nchunk\n",
    "fileno = FILENO\n",
    "print(frm)\n",
    "print(to)\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32',\n",
    "        }\n",
    "\n",
    "if VAL_RUN:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_pickle( pickle_path+\"training.pkl.gz\" )[frm:to]\n",
    "    train_df['click_time'] = pd.to_datetime( train_df.click_time )\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        public_cutoff = 10000\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )[:30000]\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "    else:\n",
    "        public_cutoff = PUBLIC_CUTOFF\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "else:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_csv(inpath+\"train.csv\", parse_dates=['click_time'], skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    else:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    train_df['click_id'] = MISSING32\n",
    "    train_df['click_id'] = train_df.click_id.astype('uint32')\n",
    "\n",
    "\n",
    "len_train = len(train_df)\n",
    "test_df['is_attributed'] = MISSING8\n",
    "test_df['is_attributed'] = test_df.is_attributed.astype('uint8')\n",
    "train_df=train_df.append(test_df)\n",
    "\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "print('Extracting new features...')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "\n",
    "print('Doing nextClick...')\n",
    "start = time.time()\n",
    "train_df['click_time'] = (train_df['click_time'].astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "train_df['nextClick'] = (train_df.groupby(['ip', 'app', 'device', 'os']).click_time.shift(-1) -train_df.click_time).astype(np.float32)\n",
    "train_df['nextClick'].fillna((train_df['nextClick'].median()), inplace=True)\n",
    "train_df['nextClick'] = train_df['nextClick'].astype(int)\n",
    "del train_df['click_time']\n",
    "print('Elapsed: {} seconds'.format(time.time() - start))\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print('Extracting aggregation features...')\n",
    "train_df = do_countuniq( train_df, ['ip'], 'channel', 'X0', 'uint8', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'app', 'X3', 'uint8', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'device', 'X5', 'uint16', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip', 'device', 'os'], 'app', 'X8', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'hour'], 'ip_tcount', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'app'], 'ip_app_count', show_max=True ); gc.collect()\n",
    "\n",
    "train_df.info()\n",
    "train_df['ip_tcount'] = train_df['ip_tcount'].astype('uint16')\n",
    "train_df['ip_app_count'] = train_df['ip_app_count'].astype('uint16')\n",
    "\n",
    "target = 'is_attributed'\n",
    "predictors= ['nextClick', 'app','device','os', 'channel', 'hour',\n",
    "              'ip_tcount',  'ip_app_count',\n",
    "              'X0', 'X3',  'X5',  'X8']\n",
    "\n",
    "print(\"label encoding....\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df[['app','device','os', 'channel', 'hour']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "print('predictors',predictors)\n",
    "\n",
    "test_df = train_df[len_train:]\n",
    "val_df = train_df[(len_train-val_size):len_train]\n",
    "y_val = val_df['is_attributed'] \n",
    "train_df = train_df[:(len_train-val_size)]\n",
    "y_train = train_df['is_attributed'] \n",
    "train_df.drop(['click_id','ip','is_attributed'],1,inplace=True)\n",
    "test_df.drop(['ip','is_attributed'],1,inplace=True)\n",
    "val_df.drop(['click_id','ip','is_attributed'],1,inplace=True)\n",
    "test_df.to_pickle('test.pkl.gz')\n",
    "\n",
    "print(\"train size: \", len(train_df))\n",
    "print(\"valid size: \", len(val_df))\n",
    "print(\"test size : \", len(test_df))\n",
    "train_df.info()\n",
    "\n",
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "print ('neural network....')\n",
    "\n",
    "max_app = np.max([train_df['app'].max(), test_df['app'].max()])+1\n",
    "max_ch = np.max([train_df['channel'].max(), test_df['channel'].max()])+1\n",
    "max_dev = np.max([train_df['device'].max(), test_df['device'].max()])+1\n",
    "max_os = np.max([train_df['os'].max(), test_df['os'].max()])+1\n",
    "max_h = np.max([train_df['hour'].max(), test_df['hour'].max()])+1\n",
    "max_nc = np.max([train_df['nextClick'].max(), test_df['nextClick'].max()])+1\n",
    "max_ipc = np.max([train_df['ip_tcount'].max(), test_df['ip_tcount'].max()])+1\n",
    "max_ipac = np.max([train_df['ip_app_count'].max(), test_df['ip_app_count'].max()])+1\n",
    "max_X0 = np.max([train_df['X0'].max(), test_df['X0'].max()])+1\n",
    "max_X3 = np.max([train_df['X3'].max(), test_df['X3'].max()])+1\n",
    "max_X5 = np.max([train_df['X5'].max(), test_df['X5'].max()])+1\n",
    "max_X8 = np.max([train_df['X8'].max(), test_df['X8'].max()])+1\n",
    "\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'nc': np.array(dataset.nextClick),\n",
    "        'ipc': np.array(dataset.ip_tcount),\n",
    "        'ipac': np.array(dataset.ip_app_count),\n",
    "        'X0': np.array(dataset.X0),\n",
    "        'X3': np.array(dataset.X3),\n",
    "        'X5': np.array(dataset.X5),\n",
    "        'X8': np.array(dataset.X8)\n",
    "    }\n",
    "    return X\n",
    "train_df = get_keras_data(train_df)\n",
    "val_df = get_keras_data(val_df)\n",
    "\n",
    "emb_n = 50\n",
    "dense_n = 1000\n",
    "in_app = Input(shape=[1], name = 'app')\n",
    "emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "in_ch = Input(shape=[1], name = 'ch')\n",
    "emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "in_dev = Input(shape=[1], name = 'dev')\n",
    "emb_dev = Embedding(max_dev, emb_n)(in_dev)\n",
    "in_os = Input(shape=[1], name = 'os')\n",
    "emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "in_h = Input(shape=[1], name = 'h')\n",
    "emb_h = Embedding(max_h, emb_n)(in_h) \n",
    "in_nc = Input(shape=[1], name = 'nc')\n",
    "emb_nc = Embedding(max_nc, emb_n)(in_nc) \n",
    "in_ipc = Input(shape=[1], name = 'ipc')\n",
    "emb_ipc = Embedding(max_ipc, emb_n)(in_ipc) \n",
    "in_ipac = Input(shape=[1], name = 'ipac')\n",
    "emb_ipac = Embedding(max_ipac, emb_n)(in_ipac) \n",
    "in_X0 = Input(shape=[1], name = 'X0')\n",
    "emb_X0 = Embedding(max_X0, emb_n)(in_X0) \n",
    "in_X3 = Input(shape=[1], name = 'X3')\n",
    "emb_X3 = Embedding(max_X3, emb_n)(in_X3) \n",
    "in_X5 = Input(shape=[1], name = 'X5')\n",
    "emb_X5 = Embedding(max_X5, emb_n)(in_X5) \n",
    "in_X8 = Input(shape=[1], name = 'X8')\n",
    "emb_X8 = Embedding(max_X8, emb_n)(in_X8) \n",
    "fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                 (emb_nc), (emb_ipc), (emb_ipac), (emb_X0), (emb_X3), (emb_X5), (emb_X8)])\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "\n",
    "x = Flatten()(s_dout)\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=[in_app,in_ch,in_dev,in_os,in_h,in_nc,in_ipc,in_ipac,in_X0,in_X3, in_X5, in_X8], outputs=outp)\n",
    "\n",
    "batch_size = 20000\n",
    "epochs = 2\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(train_df) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.001, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.001, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "class_weight = {0:.01,1:.99} # magic\n",
    "model.fit(train_df, y_train, batch_size=batch_size, class_weight=class_weight, epochs=2, shuffle=True, verbose=2, validation_data = [val_df, y_val])\n",
    "del train_df, y_train, val_df, y_val; gc.collect()\n",
    "model.save_weights('dl_support.h5')\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "test_df = pd.read_pickle('test.pkl.gz')\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "test_df.drop(['click_id'],1,inplace=True)\n",
    "test_df = get_keras_data(test_df)\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=batch_size, verbose=2)\n",
    "del test_df; gc.collect()\n",
    "print(\"writing....\")\n",
    "sub.to_csv('dl_12features_From1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
