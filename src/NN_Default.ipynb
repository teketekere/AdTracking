{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data... 115000000 175000000\n",
      "loading test data...\n",
      "Extracting new features...\n",
      "Doing nextClick...\n",
      "Elapsed: 41.00706887245178 seconds\n",
      "Extracting aggregation features...\n",
      "Counting unqiue  channel  by  ['ip'] ...\n",
      "X0 max value =  153\n",
      "Counting unqiue  app  by  ['ip'] ...\n",
      "X3 max value =  219\n",
      "Counting unqiue  device  by  ['ip'] ...\n",
      "X5 max value =  364\n",
      "Counting unqiue  app  by  ['ip', 'device', 'os'] ...\n",
      "X8 max value =  87\n",
      "Aggregating by  ['ip', 'hour'] ...\n",
      "ip_tcount max value =  69135\n",
      "Aggregating by  ['ip', 'app'] ...\n",
      "ip_app_count max value =  80634\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78790469 entries, 0 to 78790468\n",
      "Data columns (total 15 columns):\n",
      "app              uint16\n",
      "channel          uint16\n",
      "click_id         uint32\n",
      "device           uint16\n",
      "ip               uint32\n",
      "is_attributed    uint8\n",
      "os               uint16\n",
      "hour             uint8\n",
      "nextClick        int32\n",
      "X0               uint8\n",
      "X3               uint8\n",
      "X5               uint16\n",
      "X8               uint32\n",
      "ip_tcount        uint32\n",
      "ip_app_count     uint32\n",
      "dtypes: int32(1), uint16(5), uint32(5), uint8(4)\n",
      "memory usage: 3.4 GB\n",
      "label encoding....\n",
      "predictors ['nextClick', 'app', 'device', 'os', 'channel', 'hour', 'ip_tcount', 'ip_app_count', 'X0', 'X3', 'X5', 'X8']\n",
      "train size:  58000000\n",
      "valid size:  2000000\n",
      "test size :  18790469\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58000000 entries, 0 to 57999999\n",
      "Data columns (total 12 columns):\n",
      "app             uint16\n",
      "channel         uint16\n",
      "device          uint16\n",
      "os              uint16\n",
      "hour            uint8\n",
      "nextClick       int32\n",
      "X0              uint8\n",
      "X3              uint8\n",
      "X5              uint16\n",
      "X8              uint32\n",
      "ip_tcount       uint16\n",
      "ip_app_count    uint16\n",
      "dtypes: int32(1), uint16(7), uint32(1), uint8(3)\n",
      "memory usage: 1.8 GB\n",
      "Training...\n",
      "neural network....\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "app (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ch (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dev (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "os (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "nc (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ipc (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ipac (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X0 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X3 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X5 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X8 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 50)        38450       app[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 50)        24950       ch[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 50)        211400      dev[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 50)        47850       os[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 50)        1200        h[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 50)        8820050     nc[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 50)        2677500     ipc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 50)        3273200     ipac[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 50)        7700        X0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 50)        11000       X3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 50)        18250       X5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 50)        4400        X8[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 600)       0           embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "                                                                 embedding_21[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "                                                                 embedding_23[0][0]               \n",
      "                                                                 embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 600)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 600)          0           spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1000)         601000      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1000)         1001000     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            1001        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,738,951\n",
      "Trainable params: 16,738,951\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 58000000 samples, validate on 2000000 samples\n",
      "Epoch 1/2\n",
      " - 6994s - loss: 0.0015 - acc: 0.9863 - val_loss: 0.0682 - val_acc: 0.9868\n",
      "Epoch 2/2\n",
      " - 6971s - loss: 0.0013 - acc: 0.9859 - val_loss: 0.0786 - val_acc: 0.9781\n",
      "predicting....\n",
      "writing....\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Change DEBUG to False and the kernel should take 5 hours to run on Kaggle\n",
    "DEBUG = False\n",
    "WHERE = 'kaggle'\n",
    "FILENO = 4\n",
    "NCHUNK = 60000000\n",
    "OFFSET =  184903890-115000000\n",
    "VAL_RUN = False\n",
    "\n",
    "MISSING32 = 999999999\n",
    "MISSING8 = 255\n",
    "PUBLIC_CUTOFF = 4032690\n",
    "\n",
    "if WHERE=='kaggle':\n",
    "    inpath = '../input/'\n",
    "    pickle_path ='../input/'\n",
    "    suffix = ''\n",
    "    outpath = ''\n",
    "    savepath = ''\n",
    "    oofpath = ''\n",
    "    cores = 4\n",
    "elif WHERE=='gcloud':\n",
    "    inpath = '../.kaggle/competitions/talkingdata-adtracking-fraud-detection/'\n",
    "    pickle_path = '../data/'\n",
    "    suffix = '.zip'\n",
    "    outpath = '../sub/'\n",
    "    oofpath = '../oof/'\n",
    "    savepath = '../data/'\n",
    "    cores = 7\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def do_count( df, group_cols, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Aggregating by \", group_cols , '...' )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "def do_countuniq( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    if show_agg:\n",
    "        print( \"Counting unqiue \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "    \n",
    "debug = DEBUG\n",
    "if debug:\n",
    "    print('*** debug parameter set: this is a test run for debugging purposes ***')\n",
    "\n",
    "    \n",
    "if VAL_RUN:\n",
    "    nrows=122071522\n",
    "    outpath = oofpath\n",
    "else:\n",
    "    nrows=184903890\n",
    "nchunk=NCHUNK\n",
    "val_size=2000000\n",
    "frm=nrows-OFFSET\n",
    "if debug:\n",
    "    frm=0\n",
    "    nchunk=100000\n",
    "    val_size=10000\n",
    "to=frm+nchunk\n",
    "fileno = FILENO\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32',\n",
    "        }\n",
    "\n",
    "if VAL_RUN:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_pickle( pickle_path+\"training.pkl.gz\" )[frm:to]\n",
    "    train_df['click_time'] = pd.to_datetime( train_df.click_time )\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        public_cutoff = 10000\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )[:30000]\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "    else:\n",
    "        public_cutoff = PUBLIC_CUTOFF\n",
    "        test_df = pd.read_pickle( pickle_path+\"validation.pkl.gz\" )\n",
    "        test_df['click_time'] = pd.to_datetime( test_df.click_time )\n",
    "        y_test = test_df['is_attributed'].values\n",
    "        test_df.drop(['is_attributed'],axis=1,inplace=True)\n",
    "else:\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_csv(inpath+\"train.csv\", parse_dates=['click_time'], skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    else:\n",
    "        test_df = pd.read_csv(inpath+\"test.csv\", parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    train_df['click_id'] = MISSING32\n",
    "    train_df['click_id'] = train_df.click_id.astype('uint32')\n",
    "\n",
    "\n",
    "len_train = len(train_df)\n",
    "test_df['is_attributed'] = MISSING8\n",
    "test_df['is_attributed'] = test_df.is_attributed.astype('uint8')\n",
    "train_df=train_df.append(test_df)\n",
    "\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "print('Extracting new features...')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "\n",
    "print('Doing nextClick...')\n",
    "start = time.time()\n",
    "train_df['click_time'] = (train_df['click_time'].astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "train_df['nextClick'] = (train_df.groupby(['ip', 'app', 'device', 'os']).click_time.shift(-1) -train_df.click_time).astype(np.float32)\n",
    "train_df['nextClick'].fillna((train_df['nextClick'].median()), inplace=True)\n",
    "train_df['nextClick'] = train_df['nextClick'].astype(int)\n",
    "del train_df['click_time']\n",
    "print('Elapsed: {} seconds'.format(time.time() - start))\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print('Extracting aggregation features...')\n",
    "train_df = do_countuniq( train_df, ['ip'], 'channel', 'X0', 'uint8', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'app', 'X3', 'uint8', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip'], 'device', 'X5', 'uint16', show_max=True ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['ip', 'device', 'os'], 'app', 'X8', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'hour'], 'ip_tcount', show_max=True ); gc.collect()\n",
    "train_df = do_count( train_df, ['ip', 'app'], 'ip_app_count', show_max=True ); gc.collect()\n",
    "\n",
    "train_df.info()\n",
    "train_df['ip_tcount'] = train_df['ip_tcount'].astype('uint16')\n",
    "train_df['ip_app_count'] = train_df['ip_app_count'].astype('uint16')\n",
    "\n",
    "target = 'is_attributed'\n",
    "predictors= ['nextClick', 'app','device','os', 'channel', 'hour',\n",
    "              'ip_tcount',  'ip_app_count',\n",
    "              'X0', 'X3',  'X5',  'X8']\n",
    "\n",
    "print(\"label encoding....\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df[['app','device','os', 'channel', 'hour']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "print('predictors',predictors)\n",
    "\n",
    "test_df = train_df[len_train:]\n",
    "val_df = train_df[(len_train-val_size):len_train]\n",
    "y_val = val_df['is_attributed'] \n",
    "train_df = train_df[:(len_train-val_size)]\n",
    "y_train = train_df['is_attributed'] \n",
    "train_df.drop(['click_id','ip','is_attributed'],1,inplace=True)\n",
    "test_df.drop(['ip','is_attributed'],1,inplace=True)\n",
    "val_df.drop(['click_id','ip','is_attributed'],1,inplace=True)\n",
    "test_df.to_pickle('test.pkl.gz')\n",
    "\n",
    "print(\"train size: \", len(train_df))\n",
    "print(\"valid size: \", len(val_df))\n",
    "print(\"test size : \", len(test_df))\n",
    "train_df.info()\n",
    "\n",
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "print ('neural network....')\n",
    "\n",
    "max_app = np.max([train_df['app'].max(), test_df['app'].max()])+1\n",
    "max_ch = np.max([train_df['channel'].max(), test_df['channel'].max()])+1\n",
    "max_dev = np.max([train_df['device'].max(), test_df['device'].max()])+1\n",
    "max_os = np.max([train_df['os'].max(), test_df['os'].max()])+1\n",
    "max_h = np.max([train_df['hour'].max(), test_df['hour'].max()])+1\n",
    "max_nc = np.max([train_df['nextClick'].max(), test_df['nextClick'].max()])+1\n",
    "max_ipc = np.max([train_df['ip_tcount'].max(), test_df['ip_tcount'].max()])+1\n",
    "max_ipac = np.max([train_df['ip_app_count'].max(), test_df['ip_app_count'].max()])+1\n",
    "max_X0 = np.max([train_df['X0'].max(), test_df['X0'].max()])+1\n",
    "max_X3 = np.max([train_df['X3'].max(), test_df['X3'].max()])+1\n",
    "max_X5 = np.max([train_df['X5'].max(), test_df['X5'].max()])+1\n",
    "max_X8 = np.max([train_df['X8'].max(), test_df['X8'].max()])+1\n",
    "\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'nc': np.array(dataset.nextClick),\n",
    "        'ipc': np.array(dataset.ip_tcount),\n",
    "        'ipac': np.array(dataset.ip_app_count),\n",
    "        'X0': np.array(dataset.X0),\n",
    "        'X3': np.array(dataset.X3),\n",
    "        'X5': np.array(dataset.X5),\n",
    "        'X8': np.array(dataset.X8)\n",
    "    }\n",
    "    return X\n",
    "train_df = get_keras_data(train_df)\n",
    "val_df = get_keras_data(val_df)\n",
    "\n",
    "emb_n = 50\n",
    "dense_n = 1000\n",
    "in_app = Input(shape=[1], name = 'app')\n",
    "emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "in_ch = Input(shape=[1], name = 'ch')\n",
    "emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "in_dev = Input(shape=[1], name = 'dev')\n",
    "emb_dev = Embedding(max_dev, emb_n)(in_dev)\n",
    "in_os = Input(shape=[1], name = 'os')\n",
    "emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "in_h = Input(shape=[1], name = 'h')\n",
    "emb_h = Embedding(max_h, emb_n)(in_h) \n",
    "in_nc = Input(shape=[1], name = 'nc')\n",
    "emb_nc = Embedding(max_nc, emb_n)(in_nc) \n",
    "in_ipc = Input(shape=[1], name = 'ipc')\n",
    "emb_ipc = Embedding(max_ipc, emb_n)(in_ipc) \n",
    "in_ipac = Input(shape=[1], name = 'ipac')\n",
    "emb_ipac = Embedding(max_ipac, emb_n)(in_ipac) \n",
    "in_X0 = Input(shape=[1], name = 'X0')\n",
    "emb_X0 = Embedding(max_X0, emb_n)(in_X0) \n",
    "in_X3 = Input(shape=[1], name = 'X3')\n",
    "emb_X3 = Embedding(max_X3, emb_n)(in_X3) \n",
    "in_X5 = Input(shape=[1], name = 'X5')\n",
    "emb_X5 = Embedding(max_X5, emb_n)(in_X5) \n",
    "in_X8 = Input(shape=[1], name = 'X8')\n",
    "emb_X8 = Embedding(max_X8, emb_n)(in_X8) \n",
    "fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                 (emb_nc), (emb_ipc), (emb_ipac), (emb_X0), (emb_X3), (emb_X5), (emb_X8)])\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "\n",
    "x = Flatten()(s_dout)\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=[in_app,in_ch,in_dev,in_os,in_h,in_nc,in_ipc,in_ipac,in_X0,in_X3, in_X5, in_X8], outputs=outp)\n",
    "\n",
    "batch_size = 20000\n",
    "epochs = 2\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(train_df) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.001, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.001, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "class_weight = {0:.01,1:.99} # magic\n",
    "model.fit(train_df, y_train, batch_size=batch_size, class_weight=class_weight, epochs=2, shuffle=True, verbose=2, validation_data = [val_df, y_val])\n",
    "del train_df, y_train, val_df, y_val; gc.collect()\n",
    "model.save_weights('dl_support.h5')\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "test_df = pd.read_pickle('test.pkl.gz')\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "test_df.drop(['click_id'],1,inplace=True)\n",
    "test_df = get_keras_data(test_df)\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=batch_size, verbose=2)\n",
    "del test_df; gc.collect()\n",
    "print(\"writing....\")\n",
    "sub.to_csv('dl_12features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
